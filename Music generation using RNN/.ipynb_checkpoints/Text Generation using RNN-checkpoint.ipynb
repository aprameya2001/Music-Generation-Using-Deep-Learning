{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = 'tunes.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 155224 characters\n"
     ]
    }
   ],
   "source": [
    "# Read, then decode for py2 compat.\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: 1\n",
      "T:A and D\n",
      "% Nottingham Music Database\n",
      "S:EF\n",
      "M:4/4\n",
      "K:A\n",
      "M:6/8\n",
      "P:A\n",
      "f|\"A\"ecc c2f|\"A\"ecc c2f|\"A\"ecc c2f|\"Bm\"BcB \"E7\"B2f|\n",
      "\"A\"ecc c2f|\"A\"ecc c2c/2d/2|\"D\"efe \"E7\"dcB| [1\"A\"Ace a2:|\n",
      " [2\"A\"Ace ag=g||\\\n",
      "K:D\n",
      "P\n"
     ]
    }
   ],
   "source": [
    "print(text[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters is: 87\n"
     ]
    }
   ],
   "source": [
    "# Grouping all the unique characters\n",
    "vocab = sorted(set(text))\n",
    "print('Number of unique characters is: {}'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, '#': 4, '%': 5, '&': 6, \"'\": 7, '(': 8, ')': 9, '+': 10, ',': 11, '-': 12, '.': 13, '/': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, '=': 26, '>': 27, '?': 28, 'A': 29, 'B': 30, 'C': 31, 'D': 32, 'E': 33, 'F': 34, 'G': 35, 'H': 36, 'I': 37, 'J': 38, 'K': 39, 'L': 40, 'M': 41, 'N': 42, 'O': 43, 'P': 44, 'Q': 45, 'R': 46, 'S': 47, 'T': 48, 'U': 49, 'V': 50, 'W': 51, 'X': 52, 'Y': 53, '[': 54, '\\\\': 55, ']': 56, '^': 57, '_': 58, 'a': 59, 'b': 60, 'c': 61, 'd': 62, 'e': 63, 'f': 64, 'g': 65, 'h': 66, 'i': 67, 'j': 68, 'k': 69, 'l': 70, 'm': 71, 'n': 72, 'o': 73, 'p': 74, 'q': 75, 'r': 76, 's': 77, 't': 78, 'u': 79, 'v': 80, 'w': 81, 'x': 82, 'y': 83, 'z': 84, '|': 85, '~': 86}\n"
     ]
    }
   ],
   "source": [
    "# Creating a mapping table from unique characters to index\n",
    "char2idx = {ch:i for i, ch in enumerate(vocab)}\n",
    "\n",
    "# Creating a mapping from index to unique characters\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "# Representing each character in text as its integer representation\n",
    "text_as_int = np.array([char2idx[ch] for ch in text])\n",
    "\n",
    "print(char2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'X: 1\\nT:A and '  ------ is mapped to ------>> [52 25  1 16  0 48 25 29  1 59 72 62  1]\n"
     ]
    }
   ],
   "source": [
    "print(repr(text[:13]), ' ------ is mapped to ------>>', text_as_int[:13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      ":\n",
      " \n",
      "1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The maximum length sentence you want for a single input in characters\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "    print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: (101,), types: tf.int32>\n",
      "Sequence  0 :  111  :  'X: 1\\nT:A and D\\n% Nottingham Music Database\\nS:EF\\nM:4/4\\nK:A\\nM:6/8\\nP:A\\nf|\"A\"ecc c2f|\"A\"ecc c2f|\"A\"ecc c2'\n",
      "Sequence  1 :  108  :  'f|\"Bm\"BcB \"E7\"B2f|\\n\"A\"ecc c2f|\"A\"ecc c2c/2d/2|\"D\"efe \"E7\"dcB| [1\"A\"Ace a2:|\\n [2\"A\"Ace ag=g||\\\\\\nK:D\\nP:B'\n",
      "Sequence  2 :  105  :  '\\n\"D\"f2f Fdd|\"D\"AFA f2e/2f/2|\"G\"g2g ecd|\"Em\"efd \"A7\"cBA|\\n\"D\"f^ef dcd|\"D\"AFA f=ef|\"G\"gfg \"A7\"ABc |1\"D\"d'\n",
      "Sequence  3 :  111  :  '3 d2e:|2\"D\"d3 d2||\\n\\n\\n\\nX: 2\\nT:Abacus\\n% Nottingham Music Database\\nS:By Hugh Barwell, via Phil Rowe\\nM:6/'\n",
      "Sequence  4 :  106  :  '8\\nK:G\\n\"G\"g2g B^AB|d2d G3|\"Em\"GAB \"Am\"A2A|\"D7\"ABc \"G\"BAG|\\n\"G\"g2g B^AB|d2d G2G|\"Em\"GAB \"Am\"A2G|\"D7\"FGA '\n"
     ]
    }
   ],
   "source": [
    "# The batch method lets us easily convert these individual characters to sequences of the desired size.\n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "print(sequences)\n",
    "\n",
    "i=0\n",
    "for item in sequences.take(5):\n",
    "    print('Sequence ', i, ': ', len(repr(''.join(idx2char[item.numpy()]))), ' : ', repr(''.join(idx2char[item.numpy()])))\n",
    "    i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now For each sequence,\n",
    "# duplicate and shift it to form the input and target text by using the map method to apply a simple function to each batch:\n",
    "\n",
    "def split_input_sequence(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'X: 1\\nT:A and D\\n% Nottingham Music Database\\nS:EF\\nM:4/4\\nK:A\\nM:6/8\\nP:A\\nf|\"A\"ecc c2f|\"A\"ecc c2f|\"A\"ecc c'\n",
      "': 1\\nT:A and D\\n% Nottingham Music Database\\nS:EF\\nM:4/4\\nK:A\\nM:6/8\\nP:A\\nf|\"A\"ecc c2f|\"A\"ecc c2f|\"A\"ecc c2'\n"
     ]
    }
   ],
   "source": [
    "# Print the first example input and target values:\n",
    "\n",
    "for input_seq, target_seq in dataset.take(1):\n",
    "    print(repr(''.join(idx2char[input_seq.numpy()])))\n",
    "    print(repr(''.join(idx2char[target_seq.numpy()])))\n",
    "\n",
    "# Each entry in dataset is like: (input_Seq, target_Seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each index of these vectors is processed as a one time step. For the input at time step 0, the model receives the index for \"F\" and tries to predict the index for \"i\" as the next character. At the next timestep, it does the same thing but the RNN considers the previous step context in addition to the current input character."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Training Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: ((100,), (100,)), types: (tf.int32, tf.int32)>\n",
      "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "print(dataset)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use tf.keras.Sequential to define the model. For this simple example three layers are used to define our model:\n",
    "\n",
    "1. tf.keras.layers.Embedding: The input layer. A trainable lookup table that will map the numbers of each character to a vector with embedding_dim dimensions;\n",
    "2. tf.keras.layers.GRU: A type of RNN with size units=rnn_units (You can also use an LSTM layer here.)\n",
    "3. tf.keras.layers.Dense: The output layer, with vocab_size outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "        tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(vocab_size))\n",
    "        \n",
    "#         tf.keras.layers.LSTM(256, return_sequences = True, stateful = True),\n",
    "#         tf.keras.layers.Dropout(0.2),\n",
    "#         tf.keras.layers.LSTM(256, return_sequences = True, stateful = True),\n",
    "#         tf.keras.layers.Dropout(0.2),\n",
    "#         tf.keras.layers.LSTM(256, stateful = True),\n",
    "#         tf.keras.layers.Dropout(0.2),\n",
    "#         tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 87) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           22272     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (64, None, 256)           394752    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (64, None, 256)           0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (64, None, 256)           394752    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (64, None, 256)           0         \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (64, None, 256)           394752    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (64, None, 256)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, None, 87)          22359     \n",
      "=================================================================\n",
      "Total params: 1,228,887\n",
      "Trainable params: 1,228,887\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 87)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       4.465424\n"
     ]
    }
   ],
   "source": [
    "#lossfunction\n",
    "\n",
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure checkpoints\n",
    "# It is an approach where a snapshot of the state of the system is taken in case of system failure. \n",
    "# If there is a problem, not all is lost. \n",
    "# The checkpoint may be used directly, or used as the starting point for a new run, picking up where it left off.\n",
    "\n",
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints3'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 24 steps\n",
      "Epoch 1/90\n",
      "24/24 [==============================] - 39s 2s/step - loss: 3.6187\n",
      "Epoch 2/90\n",
      "24/24 [==============================] - 39s 2s/step - loss: 3.2030\n",
      "Epoch 3/90\n",
      "24/24 [==============================] - 37s 2s/step - loss: 2.7769\n",
      "Epoch 4/90\n",
      "24/24 [==============================] - 37s 2s/step - loss: 2.3865\n",
      "Epoch 5/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 2.1693\n",
      "Epoch 6/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.9604\n",
      "Epoch 7/90\n",
      "24/24 [==============================] - 37s 2s/step - loss: 1.8328\n",
      "Epoch 8/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.7336\n",
      "Epoch 9/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.6545\n",
      "Epoch 10/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.5895\n",
      "Epoch 11/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.5341\n",
      "Epoch 12/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.4937\n",
      "Epoch 13/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.4530\n",
      "Epoch 14/90\n",
      "24/24 [==============================] - 39s 2s/step - loss: 1.4197\n",
      "Epoch 15/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.3867\n",
      "Epoch 16/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.3606\n",
      "Epoch 17/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.3378\n",
      "Epoch 18/90\n",
      "24/24 [==============================] - 37s 2s/step - loss: 1.3171\n",
      "Epoch 19/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.2936\n",
      "Epoch 20/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.2739\n",
      "Epoch 21/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.2537\n",
      "Epoch 22/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.2380\n",
      "Epoch 23/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.2218\n",
      "Epoch 24/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.2068\n",
      "Epoch 25/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.1923\n",
      "Epoch 26/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.1800\n",
      "Epoch 27/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.1665\n",
      "Epoch 28/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.1542\n",
      "Epoch 29/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.1438\n",
      "Epoch 30/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.1320\n",
      "Epoch 31/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.1172\n",
      "Epoch 32/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.1082\n",
      "Epoch 33/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.0969\n",
      "Epoch 34/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.0860\n",
      "Epoch 35/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.0738\n",
      "Epoch 36/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.0632\n",
      "Epoch 37/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.0538\n",
      "Epoch 38/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.0449\n",
      "Epoch 39/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.0383\n",
      "Epoch 40/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.0277\n",
      "Epoch 41/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.0192\n",
      "Epoch 42/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.0094\n",
      "Epoch 43/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 1.0020\n",
      "Epoch 44/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.9913\n",
      "Epoch 45/90\n",
      "24/24 [==============================] - 37s 2s/step - loss: 0.9816\n",
      "Epoch 46/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.9720\n",
      "Epoch 47/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.9615\n",
      "Epoch 48/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.9556\n",
      "Epoch 49/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.9489\n",
      "Epoch 50/90\n",
      "24/24 [==============================] - 40s 2s/step - loss: 0.9423\n",
      "Epoch 51/90\n",
      "24/24 [==============================] - 39s 2s/step - loss: 0.9295\n",
      "Epoch 52/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.9245\n",
      "Epoch 53/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.9131\n",
      "Epoch 54/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.9051\n",
      "Epoch 55/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.8974\n",
      "Epoch 56/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.8933\n",
      "Epoch 57/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.8865\n",
      "Epoch 58/90\n",
      "24/24 [==============================] - 37s 2s/step - loss: 0.8771\n",
      "Epoch 59/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.8733\n",
      "Epoch 60/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.8652\n",
      "Epoch 61/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.8578\n",
      "Epoch 62/90\n",
      "24/24 [==============================] - 39s 2s/step - loss: 0.8527\n",
      "Epoch 63/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.8477\n",
      "Epoch 64/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.8452\n",
      "Epoch 65/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.8367\n",
      "Epoch 66/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.8320\n",
      "Epoch 67/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.8268\n",
      "Epoch 68/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.8239\n",
      "Epoch 69/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.8133\n",
      "Epoch 70/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.8084\n",
      "Epoch 71/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.8032\n",
      "Epoch 72/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.7899\n",
      "Epoch 73/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.7801\n",
      "Epoch 74/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.7768\n",
      "Epoch 75/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.7724\n",
      "Epoch 76/90\n",
      "24/24 [==============================] - 37s 2s/step - loss: 0.7628\n",
      "Epoch 77/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.7591\n",
      "Epoch 78/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.7541\n",
      "Epoch 79/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.7444\n",
      "Epoch 80/90\n",
      "24/24 [==============================] - 37s 2s/step - loss: 0.7404\n",
      "Epoch 81/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.7344\n",
      "Epoch 82/90\n",
      "24/24 [==============================] - 37s 2s/step - loss: 0.7331\n",
      "Epoch 83/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.7270\n",
      "Epoch 84/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.7202\n",
      "Epoch 85/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.7162\n",
      "Epoch 86/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.7181\n",
      "Epoch 87/90\n",
      "24/24 [==============================] - 37s 2s/step - loss: 0.7101\n",
      "Epoch 88/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.7041\n",
      "Epoch 89/90\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.6934\n",
      "Epoch 90/90\n",
      "24/24 [==============================] - 39s 2s/step - loss: 0.6894\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 90\n",
    "\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            22272     \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (1, None, 256)            394752    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (1, None, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (1, None, 256)            394752    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (1, None, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (1, None, 256)            394752    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (1, None, 256)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, None, 87)          22359     \n",
      "=================================================================\n",
      "Total params: 1,228,887\n",
      "Trainable params: 1,228,887\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction loop\n",
    "The following code block generates the text:\n",
    "\n",
    "1. Begin by choosing a start string, initializing the RNN state and setting the number of characters to generate.\n",
    "\n",
    "2. Get the prediction distribution of the next character using the start string and the RNN state.\n",
    "\n",
    "3. Then, use a categorical distribution to calculate the index of the predicted character. Use this predicted character as our next input to the model.\n",
    "\n",
    "4. The RNN state returned by the model is fed back into the model so that it now has more context, instead of only one character. After predicting the next character, the modified RNN states are again fed back into the model, which is how it learns as it gets more context from the previously predicted characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "\n",
    "    # Number of characters to generate\n",
    "    num_generate = 900\n",
    "    \n",
    "    # Converting the intial string into a seq of indices- vectorizing\n",
    "    input_seq = [char2idx[ch] for ch in start_string]\n",
    "    # print(input_seq)\n",
    "    input_seq = tf.expand_dims(input_seq, 0)\n",
    "    # print(input_seq)\n",
    "\n",
    "    \n",
    "    # Empty string to store our results\n",
    "    text_generated = []\n",
    "\n",
    "    # Low temperature results in more predictable text.\n",
    "    # Higher temperature results in more surprising text.\n",
    "    # Experiment to find the best setting.\n",
    "    temperature = 0.5\n",
    "    \n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    \n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_seq)\n",
    "        \n",
    "        # remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        \n",
    "        # using a categorical distribution to predict the character returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        # Pass the predicted character as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_seq = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "        \n",
    "    return (start_string + ''.join(text_generated))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# seq = generate_text(model, start_string=u\"X\")\n",
    "\n",
    "# cnt = 0\n",
    "# for i in seq:\n",
    "#     cnt += 1\n",
    "#     if i == \"\\n\" and seq[cnt] == \"\\n\":\n",
    "#         break\n",
    "            \n",
    "# temp = seq[cnt:]\n",
    "    \n",
    "# cnt = 0\n",
    "# for i in temp:        \n",
    "#     if i != '\\n':\n",
    "#         break;\n",
    "#     cnt+=1\n",
    "        \n",
    "# seq1 = temp[cnt:]\n",
    "#     #above code is for ignoring the starting string of a generated sequence. This is because we are passing any arbitrary \n",
    "#     #character to the model for generating music. Now, the model start generating sequence from that character itself which we \n",
    "#     #have passed, so first few characters before \"\\n\" contains meaningless word. Model start generating the music rhythm from\n",
    "#     #next line onwards. The correct sequence it start generating from next line onwards which we are considering.\n",
    "    \n",
    "# cnt = 0\n",
    "# for i in seq1:\n",
    "#     cnt += 1\n",
    "#     if i == \"\\n\" and seq1[cnt] == \"\\n\":\n",
    "#         break\n",
    "# seq2 = seq1[:cnt]\n",
    "#     #Now our data contains three newline characters after every tune. So, the model has leart that too. So, above code is used for\n",
    "#     #ignoring all the characters that model has generated after three new line characters. So, here we are considering only one\n",
    "#     #tune of music at a time and finally we are returning it..\n",
    "    \n",
    "# print(seq, '\\n\\n NEXT \\n\\n')\n",
    "# print(seq1, '\\n\\n NEXT \\n\\n')\n",
    "# print(seq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATED MUSICAL TUNES IN ABC NOTATION:\n",
      "\n",
      "\n",
      "Musical Tune 1 :\n",
      "\n",
      "X: 235\n",
      "T:Rosh Seele\n",
      "% Nottingham Music Database\n",
      "S:McCusker Brothers, via EF\n",
      "M:6/8\n",
      "K:G\n",
      "P:A\n",
      "|:d/2c/2|\"G\"B2B BAG|\"D7\"c2A A2A|\"G\"B2B Bcd|\"Am\"e2A \"G7\"G2g|\n",
      "\"C\"gfe c2e|\"G\"dBG GAB|\"C\"c3 -c2:|\n",
      "\n",
      "\n",
      "Musical Tune 2 :\n",
      "\n",
      "X: 115\n",
      "T:Greendim The Hunther\n",
      "% Nottingham Music Database\n",
      "S:Trad, arr Phil Rowe\n",
      "M:6/8\n",
      "K:G\n",
      "dc|\"G\"B2B BAG|\"D7\"F2A c2e|\"G\"d2B G2B|\"A7\"A2G FED|\"D7\"A2F D2d|\n",
      "\"G\"g2d B2B|\"Am\"A2G F2G|\"D7\"ABA A2B|\"G\"dBG GAB|\"Am\"c2d \"D7\"c2d|\"G\"BdG G2:|\n",
      "\n",
      "\n",
      "Musical Tune 3 :\n",
      "\n",
      "X: 225\n",
      "T:The Salling To Bader\n",
      "% Nottingham Music Database\n",
      "S:Trad, arr Phil Rowe\n",
      "M:6/8\n",
      "K:D\n",
      "A|\"D\"dfd d2f|\"A7\"ecA A2G|\"D\"FAA \"A7\"GFE|\"D\"D3 DFA|\n",
      "\"D\"d3 d2||\n",
      "\n",
      "\n",
      "Musical Tune 4 :\n",
      "\n",
      "X: 235\n",
      "T:Piddy When\n",
      "% Nottingham Music Database\n",
      "S:Trad, arr Phil Rowe\n",
      "M:6/8\n",
      "K:G\n",
      "\"G\"d2B B2d|\"C\"efg g2e|\"G\"dBG GAB|\"Am\"A3 -\"D7\"A2d|\n",
      "\"G\"dBG GBd|\"C\"efg g2e|\"G\"dBG GAB|\"Am\"c3 \"D7\"A2d|\n",
      "\"G\"g2d B2d|\"C\"cde \"G\"d2B|\"D7\"c2A A2F|\"G\"G3 G2:|\n"
     ]
    }
   ],
   "source": [
    "first_char = 'X'\n",
    "\n",
    "seq = generate_text(model, start_string=first_char)\n",
    "\n",
    "music_tunes = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "# print(seq)\n",
    "\n",
    "index1 = 0\n",
    "index2 = 0\n",
    "new_music_seq = False\n",
    "\n",
    "for i in range(len(seq)):   \n",
    "    if not new_music_seq and seq[i:i+2] == 'X:':\n",
    "        index1 = i\n",
    "        new_music_seq = True\n",
    "    \n",
    "    if new_music_seq and seq[i:i+2] == '\\n\\n':\n",
    "        index2 = i\n",
    "        music_tunes.append(seq[index1:index2])\n",
    "        new_music_seq = False\n",
    "        \n",
    "print('GENERATED MUSICAL TUNES IN ABC NOTATION:')\n",
    "for music_tune in music_tunes:\n",
    "    count += 1\n",
    "    print('\\n\\nMusical Tune', count, ':\\n')\n",
    "    print(music_tune)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
