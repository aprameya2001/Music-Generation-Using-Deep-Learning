{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "higher-candle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "\n",
    "from music21 import converter, midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "democratic-kelly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path where the model(weights only) has been stored\n",
    "checkpoint_path = \"./Model_ckpt/model_final_checkpoint\"\n",
    "\n",
    "# Path to dataset file\n",
    "path_to_file = './Dataset/tunes.txt'\n",
    "\n",
    "# Path to result directory\n",
    "path_to_result_dir = './Results'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-lover",
   "metadata": {},
   "source": [
    "# RECREATING THE MUSIC GENERATION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wrong-danish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 155224 characters\n"
     ]
    }
   ],
   "source": [
    "# Read the dataset text file and, then decode for py2 compat.\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "\n",
    "# length of text is the number of characters in the file\n",
    "print('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "closing-third",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters is: 87\n"
     ]
    }
   ],
   "source": [
    "# Grouping all the unique characters\n",
    "# 'vocab' is a set containing all unique characters present in 'text'\n",
    "vocab = sorted(set(text))\n",
    "\n",
    "print('Number of unique characters is: {}'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "chinese-giving",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a mapping table from unique characters to index\n",
    "char2idx = {ch:i for i, ch in enumerate(vocab)}\n",
    "\n",
    "# Creating a mapping from index to unique characters\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "# Representing each character in text as its integer representation\n",
    "text_as_int = np.array([char2idx[ch] for ch in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "homeless-trigger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars- or Number of unique characters\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "clinical-commitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture of the model used for music generation\n",
    "\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "        tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(vocab_size)),\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bright-committee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (1, None, 256)            22272     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (1, None, 256)            394752    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (1, None, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (1, None, 256)            394752    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (1, None, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (1, None, 256)            394752    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (1, None, 256)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, None, 87)          22359     \n",
      "=================================================================\n",
      "Total params: 1,228,887\n",
      "Trainable params: 1,228,887\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Rebuild the model by retrieving the stored weights\n",
    "\n",
    "model = build_model(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=1)\n",
    "\n",
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-premises",
   "metadata": {},
   "source": [
    "# GENERATE MUSIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "protective-version",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_music_in_ABC(model, start_string):\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "\n",
    "    # Number of characters to generate\n",
    "    num_generate = 900\n",
    "    \n",
    "    # Converting the intial string into a seq of indices- vectorizing\n",
    "    input_seq = [char2idx[ch] for ch in start_string]\n",
    "    input_seq = tf.expand_dims(input_seq, 0)\n",
    "\n",
    "    \n",
    "    # Empty string to store our results\n",
    "    text_generated = []\n",
    "\n",
    "    # Low temperature results in more predictable text.\n",
    "    # Higher temperature results in more surprising text.\n",
    "    # Experiment to find the best setting.\n",
    "    temperature = 0.5\n",
    "    \n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    \n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_seq)\n",
    "        \n",
    "        # remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        \n",
    "        # using a categorical distribution to predict the character returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        # Pass the predicted character as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_seq = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "        \n",
    "    return (start_string + ''.join(text_generated))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "distinguished-growth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATED MUSICAL TUNES IN ABC NOTATION:\n",
      "\n",
      "\n",
      "Musical Tune 1 :\n",
      "\n",
      "X: 218\n",
      "T:Nanth Skelton 1, v 2\n",
      "% Nottingham Music Database\n",
      "S:Trad, arr Phil Rowe\n",
      "M:6/8\n",
      "K:G\n",
      "D|\"G\"G2G \"D7\"AGF|\"G\"G2B \"D7\"G2A|\"G\"B2B \"D7\"cBA|\"G\"B2c \"D7\"BBc|\"G\"d2g \"D7\"dBc|\"G\"d2g \"D7\"d2c|\"G\"BAG \"D7\"AGF|\"G\"G3 G2:|\n",
      "P:B\n",
      "d/2c/2|\"G\"Bcd \"D7\"cBA|\"G\"GAG G2:|\n",
      "P:B\n",
      "d|\"G\"g2d edB|\"D7\"ded def|\"G\"g2d \"D7\"cBA|\"G\"Bcd \"D7\"cBA|\"G\"GAB \"C\"cde|\"D\"d3 -d2:|\n",
      "\n",
      "\n",
      "Musical Tune 2 :\n",
      "\n",
      "X: 233\n",
      "T:Pet\n",
      "% Nottingham Music Database\n",
      "S:Trad, arr Phil Rowe\n",
      "M:6/8\n",
      "K:D\n",
      "A|\"D\"f2e d2c|\"G\"d2B \"D\"A2F|\"G\"G3 \"D7\"G2A|\"G\"BAG \"D\"F3|\"G\"dBG DGB|dBG d3|\"Am\"\n",
      "P:A\n",
      "|:d|\"Em\"edB \"D\"def|\"G\"g2e \"Am\"cBA|\"D\"dfe \"G\"dcB|\"D7\"AGF \"G\"G2::\n",
      "A|\"G\"BAB dBd|\"C\"ece \"D7\"d2c|\"G\"Bcd \"D7\"cBA|\"G\"BGG G2:|\n",
      "\n",
      "\n",
      "Musical Tune 3 :\n",
      "\n",
      "X: 233\n",
      "T:Pit Daver and His Wife\n",
      "% Nottingham Music Database\n",
      "S:Trad, arr Phil Rowe\n",
      "M:6/8\n",
      "K:D\n",
      "A|\"D\"d2d \"A\"c2A|\"G\"BdB \"D\"AGF|\"G\"G2e \"D\"F2d|\"Em\"E2d \"A\"cBc|\n",
      "\"D\"d2d \"A\"c2A|\"G\"BdB \"D\"AGF|\"G\"G2e \"D\"F2d|\"Em\"E2d \"A\"cBc|\n",
      "\"D\"d2d \"A\"c2A|\"G\"BdB \"D\"AGF|\"G\"G2e \"D\"F2d|\"Em\"E2d \"A7\"cde|\"D\"d3 :|\n"
     ]
    }
   ],
   "source": [
    "first_char = 'X'\n",
    "\n",
    "seq = generate_music_in_ABC(model, start_string=first_char)\n",
    "\n",
    "music_tunes = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "index1 = 0\n",
    "index2 = 0\n",
    "new_music_seq = False\n",
    "\n",
    "for i in range(len(seq)):   \n",
    "    if not new_music_seq and seq[i:i+2] == 'X:':\n",
    "        index1 = i\n",
    "        new_music_seq = True\n",
    "    \n",
    "    if new_music_seq and seq[i:i+2] == '\\n\\n':\n",
    "        index2 = i\n",
    "        music_tunes.append(seq[index1:index2])\n",
    "        new_music_seq = False\n",
    "        \n",
    "print('GENERATED MUSICAL TUNES IN ABC NOTATION:')\n",
    "for music_tune in music_tunes:\n",
    "    count += 1\n",
    "    print('\\n\\nMusical Tune', count, ':\\n')\n",
    "    print(music_tune)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-carolina",
   "metadata": {},
   "source": [
    "# STORING GENERATED TUNES IN ABC & MIDI FORMATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "natural-storm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing all previously stored midi files in results directory\n",
    "\n",
    "filelist = glob.glob(os.path.join(path_to_result_dir, '*.abc'))\n",
    "\n",
    "for file in filelist:\n",
    "    os.remove(file)\n",
    "    \n",
    "filelist = glob.glob(os.path.join(path_to_result_dir, '*.mid'))\n",
    "\n",
    "for file in filelist:\n",
    "    os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "noble-quilt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Results/musical_tune_1.abc created!\n",
      "./Results/musical_tune_1.mid created!\n",
      "./Results/musical_tune_2.abc created!\n",
      "./Results/musical_tune_2.mid created!\n",
      "./Results/musical_tune_3.abc created!\n",
      "./Results/musical_tune_3.mid created!\n"
     ]
    }
   ],
   "source": [
    "# Storing the new results\n",
    "\n",
    "for i, music_tune in enumerate(music_tunes):\n",
    "    fileName = 'musical_tune_' + str(i+1) \n",
    "    \n",
    "    # Creating an abc file for current music_tune\n",
    "    abcFilePath = os.path.join(path_to_result_dir, fileName + '.abc')\n",
    "    abcFile = open(abcFilePath, 'w')\n",
    "    abcFile.write(music_tune)\n",
    "    abcFile.close()\n",
    "    print(abcFilePath, 'created!')\n",
    "    \n",
    "    # Converting the abc file into MIDI file using music21\n",
    "    midiFilePath = os.path.join(path_to_result_dir, fileName + '.mid')\n",
    "    stream = converter.parse(abcFilePath)\n",
    "    \n",
    "    try:\n",
    "        mf = midi.translate.streamToMidiFile(stream)\n",
    "        mf.open(midiFilePath, 'wb')\n",
    "        mf.write()\n",
    "        mf.close()\n",
    "        print(midiFilePath, 'created!')\n",
    "    except:\n",
    "        print(midiFilePath, 'could not be created! Please use the online abc player link given below to play the file!')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-august",
   "metadata": {},
   "source": [
    "=============================================================================== <br>\n",
    "You can also play the abc files on this site: https://editor.drawthedots.com/ <br>\n",
    "\n",
    "If an abc music tune takes too long to play on this site, just download the .wav or .midi file and run on your own music player!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-award",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
