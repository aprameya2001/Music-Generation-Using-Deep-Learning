{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "interpreted-lesson",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "from tensorflow.keras.layers import Activation, Dense, Bidirectional, LSTM, LeakyReLU, BatchNormalization, Reshape, Input\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "alpine-dietary",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_GEN_MODEL = './Models/generator_model.h5'\n",
    "PATH_TO_RESULT_DIR = './Results/'\n",
    "latent_dim = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hearing-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_file = open('notes', 'rb')\n",
    "notes = pickle.load(notes_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "shared-initial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integer to Note mapping: \n",
      "\n",
      "{0: '0.3.6', 1: '0.3.7', 2: '0.4.7', 3: '0.4.8', 4: '1.4.7', 5: '1.4.7.9', 6: '1.4.8', 7: '10.1.4.6', 8: '10.2.5', 9: '11.2.4.7', 10: '11.2.5.7', 11: '11.2.6', 12: '11.3.6', 13: '2.5.8', 14: '2.5.8.10', 15: '2.5.9', 16: '2.6.9', 17: '3.6.9.11', 18: '3.7.10', 19: '4.7.10', 20: '4.7.10.0', 21: '4.7.11', 22: '4.8.11', 23: '5.8.11', 24: '5.9.0', 25: '6.10.1', 26: '6.9.0.2', 27: '6.9.0.2.3', 28: '6.9.1', 29: '6.9.11', 30: '6.9.11.2', 31: '7.10.1', 32: '7.10.2', 33: '7.11.2', 34: '7.9.1', 35: '8.11.2.4', 36: '8.11.2.4.5', 37: '9.0.3', 38: '9.0.3.5', 39: '9.0.4', 40: '9.1', 41: '9.1.4', 42: '9.11.2.5', 43: 'A3', 44: 'A4', 45: 'A5', 46: 'B-3', 47: 'B-4', 48: 'B-5', 49: 'B3', 50: 'B4', 51: 'B5', 52: 'C#4', 53: 'C#5', 54: 'C#6', 55: 'C4', 56: 'C5', 57: 'C6', 58: 'D4', 59: 'D5', 60: 'D6', 61: 'E-4', 62: 'E-5', 63: 'E4', 64: 'E5', 65: 'F#4', 66: 'F#5', 67: 'F4', 68: 'F5', 69: 'G#3', 70: 'G#4', 71: 'G#5', 72: 'G3', 73: 'G4', 74: 'G5'}\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 100\n",
    "\n",
    "unique_notes = sorted(set(notes))\n",
    "unique_notes_count = len(unique_notes)\n",
    "\n",
    "int_to_note = dict((index, note) for index, note in enumerate(unique_notes))\n",
    "note_to_int = dict((note, index) for index, note in enumerate(unique_notes))\n",
    "\n",
    "print('Integer to Note mapping: \\n')\n",
    "print(int_to_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "organic-beads",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: ./Models/model.h5/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d5084aa5fcfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerator_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_TO_GEN_MODEL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    187\u001b[0m       \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m       \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    108\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot parse file %s: %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpath_to_pbtxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     raise IOError(\"SavedModel file does not exist at: %s/{%s|%s}\" %\n\u001b[0m\u001b[1;32m    111\u001b[0m                   (export_dir,\n\u001b[1;32m    112\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: ./Models/model.h5/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "generator_model = load_model(PATH_TO_GEN_MODEL, compile = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "formal-lodge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C#4', 'G3', 'G5', '9.11.2.5', '4.7.10', 'G5', '1.4.7', 'G3', 'G5', 'G#4', '0.3.6', 'F#4', 'G5', 'G5', '9.1.4', 'E5', 'F5', '10.2.5', 'G3', '3.6.9.11', '6.9.11.2', '6.9.1', 'E-5', '11.2.4.7', '7.9.1', '9.0.3', 'D6', '10.1.4.6', 'F5', 'G3', 'G3', 'C6', '9.0.4', 'F4', '9.11.2.5', 'G5', 'D4', '5.9.0', '0.3.6', 'G#3', '6.10.1', 'G5', 'G3', '0.3.7', 'A4', '4.7.10', '8.11.2.4', '2.5.9', 'G5', '11.2.6', '4.7.10', 'B-3', '1.4.7.9', '4.8.11', 'G4', '0.3.6', '11.3.6', '0.3.6', 'D6', 'G#5', 'G4', 'E-5', 'E4', 'G4', '7.10.1', '9.11.2.5', '0.3.6', 'D5', 'G5', 'G5', '11.2.5.7', '2.6.9', 'G5', 'G5', 'E5', 'G#5', '11.2.4.7', 'G5', 'B5', 'B4', 'G3', 'G#4', 'C#4', 'B-5', 'E-5', 'G#5', '9.0.3', 'G5', '6.10.1', 'G#3', '11.2.6', '0.3.6', '2.5.9', 'G5', 'B-4', 'C#6', 'G5', '3.6.9.11', '0.4.7', 'F5']\n"
     ]
    }
   ],
   "source": [
    "noise = np.random.normal(0, 1, (1, latent_dim))\n",
    "prediction = generator_model.predict(noise)\n",
    "predicted_notes = [x*(float(unique_notes_count)/2) +(float(unique_notes_count)/2) for x in prediction[0]]\n",
    "predicted_notes = [int_to_note[int(x)] for x in predicted_notes]\n",
    "print(predicted_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "awful-nitrogen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./Results/result_GAN_new1'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_offset = 0\n",
    "output_notes = []\n",
    "\n",
    "for element in predicted_notes:\n",
    "    item = element[0]\n",
    "    \n",
    "    # if item is a chord, i.e, if the item is a digit or it contains a dot (.)\n",
    "    if item.isdigit() or ('.' in item):\n",
    "        notes_in_chord = item.split('.')\n",
    "        extracted_notes = []\n",
    "        \n",
    "        for current_note in notes_in_chord:\n",
    "            new_note = note.Note(int(current_note))\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            extracted_notes.append(new_note)\n",
    "            \n",
    "        new_chord = chord.Chord(extracted_notes)\n",
    "        new_chord.offset = time_offset\n",
    "        output_notes.append(new_chord)\n",
    "    else:\n",
    "        # pattern is a note\n",
    "        new_note = note.Note(item)\n",
    "        new_note.offset = time_offset\n",
    "        new_note.storedInstrument = instrument.Piano()\n",
    "        output_notes.append(new_note)\n",
    "        \n",
    "    time_offset += 0.5\n",
    "\n",
    "new_midi_stream = stream.Stream(output_notes)\n",
    "new_midi_stream.write('midi', fp=PATH_TO_RESULT_DIR + 'result_GAN_new1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-release",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
